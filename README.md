# ğŸ›¡ï¸ Cyber Harassment and Abuse Detection Tool

A full-stack web application that helps detect and prevent cyber harassment in real time. This tool uses a keyword-based detection system combined with an AI model (optional) to monitor and flag abusive messages in chat environments. A built-in auto-blocking mechanism stops harmful users after repeated offenses.

---

## ğŸš€ Key Features

- ğŸ” *Real-time abuse detection* in chat messages
- ğŸ›‘ *Auto-blocking system* for repeated offenders
- ğŸ¨ *Simple and responsive chat UI* (SafeTalk)
- âš™ *Backend APIs* built using Spring Boot
- ğŸ§  *Optional AI model* integration using Flask for advanced abuse classification (future scope)

---

## ğŸ§± Tech Stack

| Layer      | Technology              |
|------------|--------------------------|
| Frontend   | React.js (SafeTalk UI)   |
| Backend    | Spring Boot (Java)       |
| AI Model   | Python + Flask (optional) |
| Database   | MySQL                    |
| Tools      | GitHub, VSCode, Postman  |

---

## ğŸ“ Folder Structure


Cyber-Harassment-and-Abuse-Detection-Tool/
â”œâ”€â”€ backend/                 # Spring Boot project
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ frontend/                # React.js app (SafeTalk)
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .vscode/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md


---

## ğŸ›  Getting Started

### ğŸ”¹ Backend (Spring Boot)

bash
cd backend
./mvnw spring-boot:run


> API will be available at: (http://localhost:8080)

---

### ğŸ”¹ Frontend (React - SafeTalk)

bash
cd frontend
npm install
npm start


> App opens at: (http://localhost:3000)

---

## ğŸ”® Future Enhancements

- ğŸ“± Mobile-friendly responsive UI
- ğŸ”” Notification system for abuse flags
- ğŸŒ Multilingual abuse filtering
- ğŸ‘® Admin panel for managing abusive words (to be developed)

---

## âš ï¸ Disclaimer

This project uses a dataset that includes terms and phrases commonly associated with harassment and abusive language for the purpose of training and evaluating detection models. These examples were included solely for academic, research, and educational use.

> We do not condone or promote any form of harassment, abuse, or offensive behavior. The dataset is used only to help machines learn how to detect and prevent such content in real-world scenarios.

If you find any content offensive, please understand that it has been included strictly for the development of a safety-focused AI system.


## ğŸ‘©â€ğŸ’» Developed By

SHRAVANI N. DESHMUKH 
Final Year B.E (IT)  
Prof. Ram Meghe Institute of Technology and Research, Amravati  
ğŸ“§ Email: shravani12d@gmail.com
ğŸ”— GitHub: https://github.com/shravani12d

---



